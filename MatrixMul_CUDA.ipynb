{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOqPej1GWzBT94RB+sRg2ne",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yashasvi281003/EE-533---CUDA-Lab/blob/main/MatrixMul_CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJgxvbv5Y7KC",
        "outputId": "94b70742-dcd2-462d-a6f0-ad343d640162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hello_world.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile hello_world.cu\n",
        "#include <stdio.h>\n",
        "__global__ void hello() {\n",
        "    printf(\"Hello World\\n\");\n",
        "}\n",
        "\n",
        "int main () {\n",
        "    printf(\"Before GPU\\n\");\n",
        "    hello<<<1,1>>>();\n",
        "    cudaDeviceReset();\n",
        "    printf(\"After GPU\\n\");\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc hello_world.cu -o hello_world\n",
        "!./hello_world"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af1wd2UQiBPp",
        "outputId": "a3bbb52a-ff9e-4e96-eb0b-9dd68ab54086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before GPU\n",
            "After GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sizetest.c\n",
        "#include <stdio.h>\n",
        "int main(){\n",
        "  printf(\"Size of system = %zu\", sizeof(int));\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0qdaWpKrz1m",
        "outputId": "e4860c57-4efa-47d8-a468-12e0159ed0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sizetest.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc sizetest.c -o sizetest\n",
        "!./sizetest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M8gg_wOuRkG",
        "outputId": "1d8a71ea-952f-4a40-e8b1-14bdc45e58a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of system = 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_gpu.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void matrixMultiplyGPU(float *A, float *B, float *C, int N) {\n",
        " int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        " int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        " if (row < N && col < N) {\n",
        " float sum = 0.0f;\n",
        " for (int k = 0; k < N; k++) {\n",
        " sum += A[row * N + k] * B[k * N + col];\n",
        " }\n",
        " C[row * N + col] = sum;\n",
        " }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    int N = (argc > 1) ? atoi(argv[1]) : 512;\n",
        "    size_t size = N * N * sizeof(float);\n",
        "\n",
        "    float *h_A = (float *)malloc(size);\n",
        "    float *h_B = (float *)malloc(size);\n",
        "    float *h_C = (float *)malloc(size);\n",
        "\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = rand() / (float)RAND_MAX;\n",
        "        h_B[i] = rand() / (float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 dimBlock(16, 16);\n",
        "    dim3 dimGrid((N + 15) / 16, (N + 15) / 16);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "    matrixMultiplyGPU<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaDeviceSynchronize();\n",
        "    float ms = 0.0f;\n",
        "    cudaEventElapsedTime(&ms, start, stop);\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "    printf(\"Naive CUDA execution time (N=%d): %.3f ms\\n\", N, ms);\n",
        "    free(h_A); free(h_B); free(h_C);\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zglzB-TI2Fga",
        "outputId": "f53ee9e1-50db-499f-f7cb-749d7b5d70dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "nvcc matrix_gpu.cu -o matrix_gpu\n",
        "for N in 8 16 32 64 128 256 400 512 562 1024 1700 1962 2048\n",
        "do\n",
        "  ./matrix_gpu $N\n",
        "done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olCctPrl3XRB",
        "outputId": "38e4e98d-c50b-461c-984b-430c9e9b7df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive CUDA execution time (N=8): 10.337 ms\n",
            "Naive CUDA execution time (N=16): 11.295 ms\n",
            "Naive CUDA execution time (N=32): 10.887 ms\n",
            "Naive CUDA execution time (N=64): 10.709 ms\n",
            "Naive CUDA execution time (N=128): 10.934 ms\n",
            "Naive CUDA execution time (N=256): 10.893 ms\n",
            "Naive CUDA execution time (N=400): 10.819 ms\n",
            "Naive CUDA execution time (N=512): 10.580 ms\n",
            "Naive CUDA execution time (N=562): 12.400 ms\n",
            "Naive CUDA execution time (N=1024): 10.426 ms\n",
            "Naive CUDA execution time (N=1700): 7.153 ms\n",
            "Naive CUDA execution time (N=1962): 7.152 ms\n",
            "Naive CUDA execution time (N=2048): 7.351 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_smt.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define TILE_WIDTH 16\n",
        "\n",
        "__global__ void matrixMultiplyTiled(float *A, float *B, float *C, int N) {\n",
        "    __shared__ float ds_A[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ float ds_B[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    int Row = by * TILE_WIDTH + ty;\n",
        "    int Col = bx * TILE_WIDTH + tx;\n",
        "\n",
        "    float Pvalue = 0.0f;\n",
        "\n",
        "    for (int m = 0; m < (N + TILE_WIDTH - 1) / TILE_WIDTH; ++m) {\n",
        "        if (Row < N && m*TILE_WIDTH + tx < N)\n",
        "            ds_A[ty][tx] = A[Row * N + m*TILE_WIDTH + tx];\n",
        "        else\n",
        "            ds_A[ty][tx] = 0.0f;\n",
        "\n",
        "        if (Col < N && m*TILE_WIDTH + ty < N)\n",
        "            ds_B[ty][tx] = B[(m*TILE_WIDTH + ty) * N + Col];\n",
        "        else\n",
        "            ds_B[ty][tx] = 0.0f;\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int k = 0; k < TILE_WIDTH; ++k)\n",
        "            Pvalue += ds_A[ty][k] * ds_B[k][tx];\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (Row < N && Col < N)\n",
        "        C[Row * N + Col] = Pvalue;\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    int N = (argc > 1) ? atoi(argv[1]) : 512;\n",
        "    size_t size = N * N * sizeof(float);\n",
        "\n",
        "    float *h_A = (float *)malloc(size);\n",
        "    float *h_B = (float *)malloc(size);\n",
        "    float *h_C = (float *)malloc(size);\n",
        "\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = rand() / (float)RAND_MAX;\n",
        "        h_B[i] = rand() / (float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 dimBlock(TILE_WIDTH, TILE_WIDTH);\n",
        "    dim3 dimGrid((N + TILE_WIDTH - 1) / TILE_WIDTH,\n",
        "                 (N + TILE_WIDTH - 1) / TILE_WIDTH);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    matrixMultiplyTiled<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    float ms;\n",
        "    cudaEventElapsedTime(&ms, start, stop);\n",
        "\n",
        "    printf(\"Optimized CUDA time (N=%d): %.3f ms\\n\", N, ms);\n",
        "\n",
        "    free(h_A); free(h_B); free(h_C);\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCN1CIZZ7O28",
        "outputId": "43cdea79-55d2-4531-c1ff-51eab01d31df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_smt.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "nvcc matrix_smt.cu -o matrix_smt\n",
        "for N in 8 16 32 64 128 256 400 512 562 1024 1700 1962 2048\n",
        "do\n",
        "  ./matrix_smt $N\n",
        "done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtwrN9CN7RpO",
        "outputId": "e2acb4f7-8ca2-42a1-a6cb-4ae5ed9f1e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized CUDA time (N=8): 7.472 ms\n",
            "Optimized CUDA time (N=16): 7.535 ms\n",
            "Optimized CUDA time (N=32): 7.352 ms\n",
            "Optimized CUDA time (N=64): 7.387 ms\n",
            "Optimized CUDA time (N=128): 7.341 ms\n",
            "Optimized CUDA time (N=256): 7.243 ms\n",
            "Optimized CUDA time (N=400): 7.353 ms\n",
            "Optimized CUDA time (N=512): 7.382 ms\n",
            "Optimized CUDA time (N=562): 7.152 ms\n",
            "Optimized CUDA time (N=1024): 7.182 ms\n",
            "Optimized CUDA time (N=1700): 7.380 ms\n",
            "Optimized CUDA time (N=1962): 7.892 ms\n",
            "Optimized CUDA time (N=2048): 7.723 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_cublas.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    int N = (argc > 1) ? atoi(argv[1]) : 512;\n",
        "    size_t size = N * N * sizeof(float);\n",
        "\n",
        "    float *h_A = (float *)malloc(size);\n",
        "    float *h_B = (float *)malloc(size);\n",
        "    float *h_C = (float *)malloc(size);\n",
        "\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = rand() / (float)RAND_MAX;\n",
        "        h_B[i] = rand() / (float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "\n",
        "    float alpha = 1.0f, beta = 0.0f;\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    cublasSgemm(handle,\n",
        "                CUBLAS_OP_N, CUBLAS_OP_N,\n",
        "                N, N, N,\n",
        "                &alpha,\n",
        "                d_B, N,\n",
        "                d_A, N,\n",
        "                &beta,\n",
        "                d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    float ms;\n",
        "    cudaEventElapsedTime(&ms, start, stop);\n",
        "\n",
        "    printf(\"cuBLAS time (N=%d): %.3f ms\\n\", N, ms);\n",
        "\n",
        "    cublasDestroy(handle);\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "    free(h_A); free(h_B); free(h_C);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4mZEyUa9miZ",
        "outputId": "245cada4-7f75-4163-f8d4-754c08bb39d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_cublas.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "nvcc matrix_cublas.cu -o matrix_cublas -lcublas\n",
        "for N in 8 16 32 64 128 256 400 512 562 1024 1700 1962 2048\n",
        "do\n",
        "  ./matrix_cublas $N\n",
        "done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-Kg0fel9pKq",
        "outputId": "3c4efa28-c01e-43a4-9e48-b4970e7dc8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuBLAS time (N=8): 48.842 ms\n",
            "cuBLAS time (N=16): 5.491 ms\n",
            "cuBLAS time (N=32): 9.968 ms\n",
            "cuBLAS time (N=64): 5.226 ms\n",
            "cuBLAS time (N=128): 7.275 ms\n",
            "cuBLAS time (N=256): 23.923 ms\n",
            "cuBLAS time (N=400): 7.315 ms\n",
            "cuBLAS time (N=512): 5.387 ms\n",
            "cuBLAS time (N=562): 6.127 ms\n",
            "cuBLAS time (N=1024): 6.416 ms\n",
            "cuBLAS time (N=1700): 9.249 ms\n",
            "cuBLAS time (N=1962): 11.226 ms\n",
            "cuBLAS time (N=2048): 11.610 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_lib.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#define TILE_WIDTH 16\n",
        "__global__ void matrixMultiplyTiled(float *A, float *B, float *C, int N) {\n",
        " __shared__ float ds_A[TILE_WIDTH][TILE_WIDTH];\n",
        " __shared__ float ds_B[TILE_WIDTH][TILE_WIDTH];\n",
        " int bx = blockIdx.x; int by = blockIdx.y;\n",
        " int tx = threadIdx.x; int ty = threadIdx.y;\n",
        " int Row = by * TILE_WIDTH + ty;\n",
        " int Col = bx * TILE_WIDTH + tx;\n",
        " float Pvalue = 0.0;\n",
        " for (int m = 0; m < (N + TILE_WIDTH - 1) / TILE_WIDTH; ++m) {\n",
        " if (Row < N && (m*TILE_WIDTH+tx) < N)\n",
        " ds_A[ty][tx] = A[Row * N + m * TILE_WIDTH + tx];\n",
        " else\n",
        " ds_A[ty][tx] = 0.0f;\n",
        " if (Col < N && (m*TILE_WIDTH+ty) < N)\n",
        " ds_B[ty][tx] = B[(m*TILE_WIDTH + ty) * N + Col];\n",
        " else\n",
        " ds_B[ty][tx] = 0.0f;\n",
        " __syncthreads();\n",
        " for (int k = 0; k < TILE_WIDTH; ++k)\n",
        " Pvalue += ds_A[ty][k] * ds_B[k][tx];\n",
        " __syncthreads();\n",
        " }\n",
        " if (Row < N && Col < N)\n",
        " C[Row * N + Col] = Pvalue;\n",
        "}\n",
        "// Exposed C function for Python\n",
        "extern \"C\" void gpu_matrix_multiply(float *h_A, float *h_B, float *h_C, int\n",
        "N) {\n",
        " size_t size = N * N * sizeof(float);\n",
        " float *d_A, *d_B, *d_C;\n",
        " cudaMalloc((void**)&d_A, size);\n",
        " cudaMalloc((void**)&d_B, size);\n",
        " cudaMalloc((void**)&d_C, size);\n",
        " cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        " cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        " dim3 dimBlock(TILE_WIDTH, TILE_WIDTH);\n",
        " dim3 dimGrid((N + TILE_WIDTH - 1) / TILE_WIDTH, (N + TILE_WIDTH - 1) /\n",
        "TILE_WIDTH);\n",
        " matrixMultiplyTiled<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);\n",
        " cudaDeviceSynchronize();\n",
        " cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        " cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFTimLLt_tmo",
        "outputId": "f0dc1521-3e7f-4ff5-c65f-31f779861f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_lib.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -Xcompiler -fPIC -shared cuda_lib.cu -o libmatrix.so"
      ],
      "metadata": {
        "id": "kvZavmny_7HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ctypes\n",
        "import numpy as np\n",
        "import time\n",
        "# Load shared library\n",
        "lib = ctypes.cdll.LoadLibrary(\"./libmatrix.so\")\n",
        "# Define argument types\n",
        "lib.gpu_matrix_multiply.argtypes = [\n",
        " np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
        " np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
        " np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
        " ctypes.c_int\n",
        "]\n",
        "\n",
        "N_values = [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
        "\n",
        "for N in N_values:\n",
        "    A = np.random.rand(N, N).astype(np.float32)\n",
        "    B = np.random.rand(N, N).astype(np.float32)\n",
        "    C = np.zeros((N, N), dtype=np.float32)\n",
        "\n",
        "    start = time.time()\n",
        "    lib.gpu_matrix_multiply(A.ravel(), B.ravel(), C.ravel(), N)\n",
        "    end = time.time()\n",
        "    print(f\"Python call to CUDA library for N={N} completed in {end - start:.4f} seconds\")"
      ],
      "metadata": {
        "id": "KMepdTorAVfX",
        "outputId": "4b00c7f0-2f9e-40dd-c1a2-053e8d17922b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python call to CUDA library for N=8 completed in 0.0012 seconds\n",
            "Python call to CUDA library for N=16 completed in 0.0004 seconds\n",
            "Python call to CUDA library for N=32 completed in 0.0004 seconds\n",
            "Python call to CUDA library for N=64 completed in 0.0005 seconds\n",
            "Python call to CUDA library for N=128 completed in 0.0006 seconds\n",
            "Python call to CUDA library for N=256 completed in 0.0005 seconds\n",
            "Python call to CUDA library for N=512 completed in 0.0015 seconds\n",
            "Python call to CUDA library for N=1024 completed in 0.0038 seconds\n",
            "Python call to CUDA library for N=2048 completed in 0.0208 seconds\n"
          ]
        }
      ]
    }
  ]
}